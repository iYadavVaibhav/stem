---
description: Data Science Learning Notes 
date: 2021-05-05
---

# Data Science

- **BERT**
  - ML Framework for **NLP**. It helps computer to **understand a language** and context of text by using surrounding text.
  - Bidirectional Encoder Representations from Transformers

- **Generative design** is a technology in which **3D models** are created and optimized by cloud computing and AI. A user sets up requirements for the model, such as manufacturing processes, loads, and constraints, and then the software offers designs that meet those requirements.

## Table of Index Kaggle

Maths:

- [Probability](https://www.kaggle.com/iyadavvaibhav/probability-notes)
- [Statistics](https://www.kaggle.com/iyadavvaibhav/statistics-the-basics)
- [Statistics Advance](https://www.kaggle.com/iyadavvaibhav/statistics-distributions-nrml-clt-conf-int) - Distributions

Data ETL EDA Wrangling

- [Python Notes](https://www.kaggle.com/iyadavvaibhav/python-notes) - Data Structures
- [Pandas Notes](https://www.kaggle.com/iyadavvaibhav/pandas-notes) - Series, DataFrame, Heirarchy
- [Data Handling](https://www.kaggle.com/iyadavvaibhav/data-handling-notes/) - Pre-Processing, EDA, Transformation
- Dimentionality Reduction - PCA, LDA, Kernel PCA

[Regression](https://www.kaggle.com/iyadavvaibhav/ml-regression-theory) - supervised:

- Linear Regression
- Simple Linear Regression
- Multiple Linear Regression
- Polynomial Linear Regression
- Support Vector Regression
- Decision Tree Regression
- Random Forest Regression

[Classification](https://www.kaggle.com/iyadavvaibhav/ml-classification-theory) - supervised:

- Logistic Regression - confusion matrix, accuracy, sigmoid, CAP Curve
- KNN - K Nearest Neighbour Classifier - Euclidean distance
- SVM - Support Vector Machines - Maximum Margin Hyperplane
- Kernel SVM - Map to Higher Dimention, Kernel Trick, Gaussian RBF Kernel
- Naive Bayes - Bayes Theorem
- Decision Tree Classifier
- Random Forest Classifier - entropy, ensemble learning

[Clustering](https://www.kaggle.com/iyadavvaibhav/ml-clustering-theory) - unsupervised:

- K-Means Clustering - wcss, choosing k-value, k-means++
- Hierarchical Clustering - Agglomerative, Dendrogram

[Association Rule](https://www.kaggle.com/iyadavvaibhav/ml-association-rule-learning-notes) - Unsupervised:

- Apriori Algorithm - market basket analysis, lift, support, confidence, todo
- Eclat (Part 5 todo)
- FP Growth

Other Bonus Extra:

- Model Select
- Reinforcement Learning (Part 6 todo)
  - Upper Confidence Bound
  - Thompson Sampling

[NLP](https://www.kaggle.com/iyadavvaibhav/ml-nlp-notes):

- Cleaning, stemming, nltk, bag of words, tokenization

Deep Learning: (Part 8 todo)

[Dimentionality Reduction](https://www.kaggle.com/iyadavvaibhav/ml-dimentionality-reduction-notes):

- PCA - max variance, unsupervised
- LDA - max class separation, supervised
- Kernel PCA - kernel trick on non-linearly separable dataset
- SVD
- GDA - Generalized Discriminant Analysis
